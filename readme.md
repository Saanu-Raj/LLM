# ğŸ©º TinyLlama Medical Assistant

A fine-tuned TinyLlama 1.1B model specialized in allopathic medicine, trained using LoRA (Low-Rank Adaptation) on a custom medical dataset.

## ğŸ¯ Features

- **Fine-tuned Model**: Specialized knowledge of 10+ common medicines
- **LoRA Adaptation**: Efficient fine-tuning with only 2.2M trainable parameters
- **4-bit Quantization**: Memory-efficient inference
- **User Authentication**: Role-based access (admin, doctor, student)
- **Medical Disclaimer**: Safety warnings on all responses
- **Interactive UI**: Clean Streamlit interface with adjustable parameters

## ğŸ“Š Model Details

- **Base Model**: TinyLlama-1.1B-Chat-v1.0
- **Fine-tuning Method**: LoRA (r=8, alpha=16)
- **Training Data**: 500 medical Q&A pairs
- **Training Accuracy**: 97.83%
- **Medicines Covered**: Paracetamol, Ibuprofen, Amoxicillin, Metformin, Atorvastatin, Amlodipine, Omeprazole, Cetirizine, Azithromycin, Losartan

## ğŸš€ Quick Start

### Local Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/medical-assistant.git
cd medical-assistant

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
```

### Login Credentials

```
Username: admin     Password: admin123
Username: doctor    Password: doc123
Username: student   Password: student123
```

## ğŸ“ Project Structure

```
medical-assistant/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml                # Streamlit configuration
â”œâ”€â”€ tinyllama-medical-lora/        # Fine-tuned model weights
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â””â”€â”€ tokenizer files...
â””â”€â”€ README.md
```

## ğŸ’¡ Example Queries

- "What is Paracetamol used for?"
- "Tell me about Ibuprofen"
- "What is Metformin?"
- "Uses of Amoxicillin"
- "What is Atorvastatin for?"

## âš™ï¸ Model Parameters

Adjust these in the sidebar:
- **Temperature** (0.1-1.5): Controls randomness
- **Max Tokens** (32-256): Response length
- **Top-p** (0.1-1.0): Nucleus sampling

## âš ï¸ Medical Disclaimer

This AI assistant is for educational purposes only. Always consult a qualified healthcare provider for medical advice.

## ğŸ”§ Technical Stack

- **Framework**: Streamlit
- **Model**: TinyLlama 1.1B + LoRA
- **Libraries**: Transformers, PEFT, BitsAndBytes, PyTorch
- **Quantization**: 4-bit NF4

## ğŸ“„ License

MIT License

## ğŸ‘¥ Authors

Your Name - Medical AI Research

## ğŸ™ Acknowledgments

- TinyLlama team for the base model
- Hugging Face for transformers library
- PEFT library for LoRA implementation
